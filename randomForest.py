# -*- coding: utf-8 -*-
"""randomForest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QdxmWSviH4wcxVhQP1oOEx2fNI7BC8f4
"""

# Load libraries
import pandas as pd
from sklearn.ensemble import RandomForestClassifier # Import Random Forest Classifier
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics #Import scikit-learn metrics module for calculating the various required metrics calculation
import matplotlib.pyplot as plt
# Read the dataset and look at the head to gague the column names and whether column names actually exists
df_rf = pd.read_csv('./diabetes.csv')
df_rf.head()
# Perform the basic Null Check to decide whether imputation or drop is required
df_rf.isnull().sum()

X = df_rf.drop('Outcome', axis=1)
y = df_rf['Outcome']
print(X)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
# Create Random Forest classifer object - change hyper params and get different results maybe answer with best values
# Play around with the values of the RandomForestClassifier - change criterion and max_depth to find the best f1 score
# Prescribed values - criterion = "gini", min_samples_leaf = 1, min_samples_split = 10, max_features='auto', random_state=1
criterion = "gini"
min_samples_leaf = 1
min_samples_split = 10
max_features = 'auto'
random_state = 1
rf_clf = RandomForestClassifier(criterion=criterion,
                                min_samples_leaf=min_samples_leaf,
                                min_samples_split=min_samples_split,
                                max_features=max_features,
                                random_state=random_state)
# Train and fit Random Forest Classifer
rf_clf.fit(X_train, y_train)
# Predict the response for test dataset
y_pred = rf_clf.predict(X_test)
# Report the accuracy, precision, recall and f1_score into the variables labelled thus - you may try out various combinations referring here: https://scikit- learn.org/stable/modules/classes.html#classification-metrics
rf_y_true = y_test
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1_score = f1_score(y_test, y_pred, average='weighted')
print("Accuracy:", accuracy) # -- 1.1
print("Precision Score:", precision) # -- 1.2
print("Recall Score: ", recall) # -- 1.3
print("F1 Score: ", f1_score) # -- 1.4

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

def plot_roc(rf_y_true, rf_probs):
    rf_fpr, rf_tpr, rf_threshold = roc_curve(rf_y_true, rf_probs)
    rf_auc_val = auc(rf_fpr, rf_tpr)

    # Plotting the ROC curve
    plt.plot(rf_fpr, rf_tpr, label='AUC=%0.2f' % rf_auc_val, color='darkorange')
    plt.legend(loc='lower right')
    plt.plot([0, 1], [0, 1], 'b--')
    plt.xlim([0, 1])
    plt.ylim([0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.show()

    return rf_auc_val

from sklearn.metrics import roc_auc_score

# Calculate the predicted probabilities
rf_probs = rf_clf.predict_proba(X_test)[:, 1]

# Use the plot_roc function
rf_auc = plot_roc(rf_y_true, rf_probs)

# Report AUC value
print('AUC=%0.2f' % rf_auc)

from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score


max_acc, best_k = 0, 0

for k in range(2, 11):
    skfold = StratifiedKFold(n_splits=k, random_state=100, shuffle=True)
    results_skfold_acc = (cross_val_score(rf_clf, X, y, cv=skfold)).mean() * 100.0

    if results_skfold_acc > max_acc:
        max_acc = results_skfold_acc
        best_k = k

best_accuracy = max_acc# Put the accuracy score here from the values that you got -- 1.6 of Gradescope tests
best_k_fold = best_k# Put the value of k that gives the best accuracy here # -- 1.7 of Gradescope tests
print(best_accuracy, best_k_fold)